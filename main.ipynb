{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import sys, pdb\n",
    "import copy, time\n",
    "import json, random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from colorama import Style, Fore\n",
    "# %matplotlib inline ipnyb\n",
    "\n",
    "from dataloader.my_loader import MyDataLoader\n",
    "from dataloader.OAutoEncoder_loader import ARCDataset\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from visualization.my_vis import ARCPlottor\n",
    "\n",
    "\n",
    "from models.O_Auto_Encoder import *\n",
    "\n",
    "for dirname, _, filenames in os.walk('/home/hyunseok/enssamble/settings'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "local_path = \"/home/hyunseok/enssamble/data/kaggle/\"\n",
    "with open(\"/home/hyunseok/enssamble/settings/kaggle_data_file_name.json\",'r') as file:\n",
    "    path_dict = json.load(file)\n",
    "    data = MyDataLoader(\"arcprize\", path_dict, local_path) \n",
    "    data.cur_data_mode(\"train\")\n",
    "\n",
    "plotter = ARCPlottor()\n",
    "\n",
    "\n",
    "cmap = colors.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "\n",
    "norm = colors.Normalize(vmin=0, vmax=9)\n",
    "color_list = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -pthread -lpthread -O3 -std=c++17 -o ./cookedModels/SkleanTree ./models/SkleanTree.cpp\n",
    "!./cookedModels/SkleanTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FOLDER = '/home/hyunseok/enssamble/data/kaggle/'\n",
    "file_list = [\n",
    "    f'{BASE_FOLDER}/arc-agi_training_challenges.json',\n",
    "    f'{BASE_FOLDER}/arc-agi_evaluation_challenges.json',\n",
    "    f'{BASE_FOLDER}/arc-agi_test_challenges.json'\n",
    "\n",
    "]\n",
    "def auto_encoder():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "\n",
    "    norm = colors.Normalize(vmin=0, vmax=10)\n",
    "\n",
    "    train_dataset = ARCDataset(file_list)\n",
    "    train_dataset.set_dataset()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "    Dimension = train_dataset.dim\n",
    "    Keys = train_dataset.keys\n",
    "\n",
    "    IN_DIM = 100 + 1\n",
    "    OUT_DIM = 100\n",
    "    LATENT_DIM = 1024\n",
    "    model = LSTM(IN_DIM, OUT_DIM, LATENT_DIM).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    training = Training(model, train_loader, criterion, optimizer, device)\n",
    "    training.train()\n",
    "\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "    sanity = Prediction(model, train_dataset, Dimension, cmap, norm, device)\n",
    "    def plot_pic(x):\n",
    "        plt.imshow(np.array(x), cmap=cmap, norm=norm)\n",
    "        plt.show()\n",
    "    for i in range(100):\n",
    "        result = sanity.predict(model,[sanity.data.data[i][1],sanity.data.data[i][2]])\n",
    "        print(result)\n",
    "        output1 = sanity.remove_tail_zeros(sanity.data.data[i][0], torch.round(result * 9), 'out')\n",
    "        plot_pic(output1)\n",
    "# for i in range(len(pred.data)):\n",
    "#     result = pred.predict(model,[pred.data.data[i][1],pred.data.data[i][2]])\n",
    "#     output1 = pred.remove_tail_zeros(pred.data.data[i][0], torch.round(result * 9), 'out')\n",
    "#     plot_pic(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.symmetry_repariring import *\n",
    "from models.color_counter import *\n",
    "from models.different_solvers import *\n",
    "from models.via_tree import *\n",
    "from cookedModels.utils import *\n",
    "from visualization.my_vis import *\n",
    "\n",
    "from checker.checker import depency_inject_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def make_submission_file(data, solver_name, dataloader, data_mode):\n",
    "    now = datetime.now()\n",
    " \n",
    "\n",
    "    metadata = {\n",
    "        \"date\": now.strftime(\"%Y-%m-%d\"),  # YYYY-MM-DD 형식\n",
    "        \"time\": now.strftime(\"%H:%M:%S\"),   # HH:MM:SS 형식\n",
    "        \"data_mode\": data_mode,\n",
    "        \"solver_name\": solver_name,\n",
    "    } \n",
    "    json_file_data = {\n",
    "        'metadata': metadata,\n",
    "        'submission': data\n",
    "    }\n",
    "\n",
    "    # JSON 파일로 저장\n",
    "    with open('./data/submissions/{}-{}-{}-{}.json'.format(metadata['date'], metadata['time'],metadata['data_mode'], metadata['solver_name'] ), 'w') as json_file:\n",
    "        json.dump(json_file_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mode = \"evaluation\"\n",
    "\n",
    "f1 = lambda test_input: predict_repeating(test_input)\n",
    "f2 = lambda task, test_input: predict_transforms_grid_2x(task, test_input)\n",
    "f3 = lambda x: predict_chess(grid_filter(x))\n",
    "f4 = lambda task, test_input: predict_tiles_shape(task, test_input)\n",
    "f5 = lambda task,test_input: predict_grid_transforms(task, test_input)\n",
    "f6 = lambda test_input: predict_repeating_mask(test_input)\n",
    "\n",
    "fdata1 = depency_inject_funcs( data, data_mode, f1, [(check_repeating, [True], {})])\n",
    "fdata2 = depency_inject_funcs( data, data_mode, f2, [(check_grid, [], {}),(check_sub_grid_2x,[],{})])\n",
    "fdata3 = depency_inject_funcs( data, data_mode, f3, [(check_grid, [], {}),(check_chess,[ False, True],{})])\n",
    "fdata4 = depency_inject_funcs( data, data_mode, f4, [(check_tiles_shape, [True], {})],[],{})\n",
    "fdata5 = depency_inject_funcs( data, data_mode, f5, [(check_grid, [], {}), (check_grid_transforms,[],{})])\n",
    "fdata6 = depency_inject_funcs( data, data_mode, f6, [(check_sub_mask, [], {})])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cookedModels.colors_counter import *\n",
    "from cookedModels.symmetry_repairing import *\n",
    "from cookedModels.sklearn_tree import * \n",
    "\n",
    "store1 = {}\n",
    "store2 = {}\n",
    "store3 = {}\n",
    "for task_id in data.cur_problem:\n",
    "    task = data.cur_problem[task_id]\n",
    "    for i in range(len(task['test'])):\n",
    "        test_input = np.array(task['test'][i]['input'])\n",
    "        prn = []\n",
    "        ganswer = []\n",
    "        cooked_symmetry_repairing(store1, task, task_id, i, ganswer, prn, pic_mode=True)\n",
    "        prn = []\n",
    "        ganswer = []\n",
    "        cooked_color_counter(store2, task, task_id, i, ganswer, prn, pic_mode=True)\n",
    "        prn = []\n",
    "        ganswer = []\n",
    "        cooked_sklearn_tree(store3, task, test_input, task_id, prn, pic_mode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cookedModels.arc_dsl_solvers import sub_arc_dsl, cooked_arc_dsl_solvers\n",
    "from dataloader.my_loader import *\n",
    "from models.arcdsls import solvers\n",
    "\n",
    "store6 = {}\n",
    "cooked_arc_dsl_solvers(store6, data, data_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mode = \"evaluation\"\n",
    "\n",
    "make_submission_file(fdata1, \"predict_repeating\", data, data_mode)\n",
    "make_submission_file(fdata2, \"predict_transforms_grid_2x\", data, data_mode)\n",
    "make_submission_file(fdata3, \"predict_chess\", data, data_mode)\n",
    "make_submission_file(fdata4, \"predict_tiles_shape\", data, data_mode)\n",
    "make_submission_file(fdata5, \"predict_grid_transforms\", data, data_mode)\n",
    "make_submission_file(fdata6, \"predict_repeating_mask\", data, data_mode)\n",
    "\n",
    "make_submission_file(store1, \"symmetry_repairing\", data, data_mode)\n",
    "make_submission_file(store2, \"colors_counter\", data, data_mode)\n",
    "make_submission_file(store3, \"sklearn_tree\", data, data_mode)\n",
    "make_submission_file(store6, \"arc_dsl_solvers\", data, data_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arc-agi_training_solutions.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m                     wrong \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;28mprint\u001b[39m(right, wrong, \u001b[38;5;28mlen\u001b[39m(guess[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission\u001b[39m\u001b[38;5;124m'\u001b[39m][key]))\n\u001b[0;32m---> 31\u001b[0m \u001b[43mcheck_submissions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mcheck_submissions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     guess \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     17\u001b[0m data_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mcur_data_mode(data_mode)\n\u001b[1;32m     19\u001b[0m data\u001b[38;5;241m.\u001b[39mcur_target_goal\n\u001b[1;32m     21\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def compare_2d_lists(list1, list2):\n",
    "    return np.array_equal(np.array(list1), np.array(list2))\n",
    "\n",
    "def check_submissions():\n",
    "    for dirname, _, filenames in os.walk('./data'):\n",
    "        for filename in filenames:\n",
    "          \n",
    "            path = os.path.join(dirname, filename)\n",
    "            print(filename)\n",
    "            \n",
    "            with open(path,'r') as file:\n",
    "                guess = json.load(file)\n",
    "            data_mode='evaluation'\n",
    "            data.cur_data_mode(data_mode)\n",
    "            data.cur_target_goal\n",
    "\n",
    "            right = 0\n",
    "            wrong = 0\n",
    "            for key in guess['submission']:\n",
    "                if(compare_2d_lists(data.cur_target_goal[key][0], guess['submission'][key][0])):\n",
    "                    right += 1\n",
    "                else:\n",
    "                    wrong += 1\n",
    "\n",
    "            print(right, wrong, len(guess['submission'][key]))\n",
    "\n",
    "check_submissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "# Function to translate from old submission format (csv) to new one (json)\n",
    "def translate_submission(file_path,output_name):\n",
    "    # Read the original submission file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    submission_dict = {}\n",
    "\n",
    "    for line in lines[1:]:  # Skip the header line\n",
    "        output_id, output = line.strip().split(',')\n",
    "        task_id, output_idx = output_id.split('_')\n",
    "        predictions = output.split(' ')  # Split predictions based on ' '\n",
    "\n",
    "        # Take only the first two predictions\n",
    "        if len(predictions) > 2:\n",
    "            predictions = predictions[:2]\n",
    "\n",
    "        processed_predictions = []\n",
    "        for pred in predictions:\n",
    "            if pred:  # Check if pred is not an empty string\n",
    "                pred_lines = pred.split('|')[1:-1]  # Remove empty strings from split\n",
    "                pred_matrix = [list(map(int, line)) for line in pred_lines]\n",
    "                processed_predictions.append(pred_matrix)\n",
    "\n",
    "        attempt_1 = processed_predictions[0] if len(processed_predictions) > 0 else []\n",
    "        attempt_2 = processed_predictions[1] if len(processed_predictions) > 1 else []\n",
    "\n",
    "        if task_id not in submission_dict:\n",
    "            submission_dict[task_id] = []\n",
    "\n",
    "        attempt_dict = {\n",
    "            \"attempt_1\": attempt_1,\n",
    "            \"attempt_2\": attempt_2\n",
    "        }\n",
    "\n",
    "        if output_idx == '0':\n",
    "            submission_dict[task_id].insert(0, attempt_dict)\n",
    "        else:\n",
    "            submission_dict[task_id].append(attempt_dict)\n",
    "\n",
    "    # Write to the new json file\n",
    "    with open(output_name, 'w') as file:\n",
    "        json.dump(submission_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from glob import glob\n",
    "\n",
    "#######################################################################################\n",
    "# Adapt ARC Prize 2024 files to work with Abstraction and Resoning Corpus 2020 rules ##\n",
    "#######################################################################################\n",
    "\n",
    "def mySystem(cmd):\n",
    "    print(cmd)\n",
    "    process = Popen(cmd, stdout=PIPE, stderr=STDOUT, shell=True)\n",
    "    for line in iter(process.stdout.readline, b''):\n",
    "        print(line.decode(\"utf-8\"), end='')\n",
    "    assert(process.wait() == 0)\n",
    " \n",
    "############################################\n",
    "# Beginning of icecuber's original solution#\n",
    "##########################################\n",
    " \n",
    "\n",
    "def mySystem(cmd):\n",
    "    print(cmd)\n",
    "    process = Popen(cmd, stdout=PIPE, stderr=STDOUT, shell=True)\n",
    "    for line in iter(process.stdout.readline, b''):\n",
    "        print(line.decode(\"utf-8\"), end='')\n",
    "    assert(process.wait() == 0)\n",
    "    \n",
    "dummy_run = False\n",
    "\n",
    "\n",
    "# for fn in glob(\"/kaggle/working/abstraction-and-reasoning-challenge/test/*.json\"):\n",
    "#     if \"136b0064\" in fn:\n",
    "#         print(\"Making dummy submission\")\n",
    "#         f = open(\"old_submission.csv\", \"w\")\n",
    "#         f.write(\"output_id,output\\n\")\n",
    "#         f.close()\n",
    "#         dummy_run = True\n",
    "\n",
    "#   mySystem(\"cp -r ./archive absres-c-files\")\n",
    "#   mySystem(\"cd absres-c-files; make -j\")\n",
    "#   mySystem(\"cd absres-c-files; python3 safe_run.py\")\n",
    "#   mySystem(\"cp absres-c-files/submission_part.csv old_submission.csv\")\n",
    "#   mySystem(\"tar -czf store.tar.gz absres-c-files/store\")\n",
    "#   mySystem(\"rm -r absres-c-files\")\n",
    "\n",
    "if not dummy_run:\n",
    "  mySystem(\"ls\")\n",
    "  mySystem(\"cd ./models/ice-cuber; make -j\")\n",
    "  mySystem(\"cd ./models/ice-cuber; python3 safe_run.py\")\n",
    "\n",
    "#   mySystem(\"cd ./models/ice-cube; python3 safe_run.py\")\n",
    "#   mySystem(\"cp ./models/ice-cube/submission_part.csv ./old_submission.csv\")\n",
    "#   mySystem(\"rm -r absres-c-files\")\n",
    "\n",
    "# Function to translate from old submission format (csv) to new one (json)\n",
    "def translate_submission(file_path):\n",
    "    # Read the original submission file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    submission_dict = {}\n",
    "\n",
    "    for line in lines[1:]:  # Skip the header line\n",
    "        output_id, output = line.strip().split(',')\n",
    "        task_id, output_idx = output_id.split('_')\n",
    "        predictions = output.split(' ')  # Split predictions based on ' '\n",
    "        \n",
    "        # Take only the first two predictions\n",
    "        if len(predictions) > 2:\n",
    "            predictions = predictions[:2]\n",
    "\n",
    "        processed_predictions = []\n",
    "        for pred in predictions:\n",
    "            if pred:  # Check if pred is not an empty string\n",
    "                pred_lines = pred.split('|')[1:-1]  # Remove empty strings from split\n",
    "                pred_matrix = [list(map(int, line)) for line in pred_lines]\n",
    "                processed_predictions.append(pred_matrix)\n",
    "\n",
    "        attempt_1 = processed_predictions[0] if len(processed_predictions) > 0 else []\n",
    "        attempt_2 = processed_predictions[1] if len(processed_predictions) > 1 else []\n",
    "\n",
    "        if task_id not in submission_dict:\n",
    "            submission_dict[task_id] = []\n",
    "\n",
    "        attempt_dict = {\n",
    "            \"attempt_1\": attempt_1,\n",
    "            \"attempt_2\": attempt_2\n",
    "        }\n",
    "\n",
    "        if output_idx == '0':\n",
    "            submission_dict[task_id].insert(0, attempt_dict)\n",
    "        else:\n",
    "            submission_dict[task_id].append(attempt_dict)\n",
    "    \n",
    "    # Write to the new json file\n",
    "    with open('sub_icecube.json', 'w') as file:\n",
    "        json.dump(submission_dict, file, indent=4)\n",
    "\n",
    "translate_submission('/kaggle/working/old_submission.csv')\n",
    "\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enssamble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
